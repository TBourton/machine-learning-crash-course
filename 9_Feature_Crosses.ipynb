{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "supposed-complex",
   "metadata": {},
   "source": [
    "# Feature Crosses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "green-mexican",
   "metadata": {},
   "source": [
    "### This is a linear problem:\n",
    "\n",
    "<img src=\"images/LinearProblem1.png\">\n",
    "\n",
    "It's easy to draw a line (namely $\\mathcal{C}: x_1=-x_2$ with $x_1$ running vertically and $x_2$ horizontally and $(0,0)$ in the middle of the picture) that seperates blue from orange.\n",
    "\n",
    "In this case our model would just be something like $y=sign(x_1 + x_2)$ (or actually it's smooth version $y=\\tanh(kx)$, with $x=x_1+x_2$ and $k$ some large integer)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optimum-silver",
   "metadata": {},
   "source": [
    "### However this is not a linear problem\n",
    "(in the space $(x_1, x_2)$, at least).\n",
    "\n",
    "<img src=\"images/LinearProblemNot.png\">\n",
    "\n",
    "This line (curve) that seperates these would actually be described by something like $\\mathcal{C}: x_1x_2=\\epsilon$ with $\\epsilon$ some very small but non-zero number. This is clearly non linear.\n",
    "\n",
    "We can introduce a new feature $x_3=x_1x_2$ though. Notice that since $x_3>0$ iff $x_1>0$ and $x_2>0$ or $x_1<0$ and $x_2<0$. Our model would turn our to be something like $y=\\tanh(kx_3)$.\n",
    "\n",
    "Notice that this is nothing but a nice change of variables into a linear space. Namely the curve $\\mathcal{C}:x_1x_2=\\epsilon$ just becomes $\\mathcal{C}: x_3=\\epsilon$ which is just a linear relationship."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "operating-maker",
   "metadata": {},
   "source": [
    "This is the exact thing about linear regression. The predictor can model only linear relationships between features. However those features themselves do not have to be linear. You can take any non linear combination of the features that you like and put them into your linear regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "japanese-greensboro",
   "metadata": {},
   "source": [
    "### Examples\n",
    "\n",
    "* Housing market price predictor: `latitude` $\\times$ `num_bedrooms` - 3 bedrooms in new york is different from 3 bedrooms somewhere else\n",
    "* tic-tac-toe predictor: `pos_1`$\\times$ `pos_2` $\\times\\dots\\times$ `pos_9`: overall context of other plays matters here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "specified-nickel",
   "metadata": {},
   "source": [
    "## Why?\n",
    "\n",
    "* Lets us use linear learners for non-linear data\n",
    "* Scale well to massive datasets\n",
    "* Increases model expressitivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "competitive-collectible",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
