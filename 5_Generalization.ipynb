{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "referenced-colorado",
   "metadata": {},
   "source": [
    "# Generalisaton"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "portable-namibia",
   "metadata": {},
   "source": [
    "We want ML models to generalise to new, unseen data. Overfitting is when the training learns peculiarities about the training data.\n",
    "\n",
    "Goal: predict well on new data drawn from (hidden) true distribution\n",
    "We only get to sample this distibution\n",
    "\n",
    "Ockham's Razor principle: \n",
    "*The less complex a model is, the more likely that a good empirical result is not just due to the peculiarites of our sample.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "downtown-campbell",
   "metadata": {},
   "source": [
    "Test set methodology: reserve some training samples for testing.\n",
    "\n",
    "Hence, assume:\n",
    "1. Exmaples are drawn (independently and identically) i.i.d at random from the distibution\n",
    "2. Distribution is always stationary\n",
    "3. We always pull from same distribution (train/val/test sets are all from the same distibution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verified-characterization",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
